{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1.txt') as numberfile:\n",
    "    numbers = np.array(numberfile.read().split(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    if (product := numbers[numbers + i == 2020] * i).size > 0:\n",
    "        print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(numbers):\n",
    "    for m in numbers[i:]:\n",
    "        if (product := numbers[numbers + n + m == 2020] * n * m).size > 0:\n",
    "            print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = pd.read_csv('2.txt', sep=' |-|: ', \n",
    "                        names=['min_counts', 'max_counts', 'character', 'password'], \n",
    "                        engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if entry.min_counts <= entry.password.count(entry.character) <= entry.max_counts:\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords.rename(columns={'min_counts': 'first_index', 'max_counts': 'last_index'}, inplace=True)\n",
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if (entry.password[entry.first_index-1] == entry.character) ^ (entry.password[entry.last_index-1] == entry.character):\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counter = 0\n",
    "index = 0\n",
    "slope = 3\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += (row[index] == '#')\n",
    "        index = (index + slope) % (len(row))\n",
    "print(tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = np.arange(1, 8, 2, dtype='int64')\n",
    "index = np.zeros_like(slope)\n",
    "tree_counter = np.zeros_like(slope)\n",
    "\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += [row[i] == '#' for i in index]\n",
    "        index = (index + slope) % (len(row))\n",
    "\n",
    "# Special case\n",
    "s_slope = 1\n",
    "s_index = 0\n",
    "s_tree_counter = 0\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in itertools.islice(tree_pattern_file, 0, None, 2):\n",
    "        row = row[:-1]\n",
    "        s_tree_counter += (row[s_index] == '#')\n",
    "        s_index = (s_index + s_slope) % (len(row))\n",
    "print(tree_counter.prod() * s_tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "pass_port_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    valid_passports += all(key in p_info for key in pass_port_keys)\n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(passport_info):\n",
    "    for info in passport_info.split():\n",
    "        yield info.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "passport_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    p_info_dict = {key: value for key, value in create_dict(p_info)}\n",
    "    # Guard clauses for input validation\n",
    "    try:\n",
    "        if not (set(p_info_dict.keys()) | set(('cid',))) == set(passport_keys):\n",
    "            continue\n",
    "        elif not 1920 <= int(p_info_dict['byr']) <= 2002:\n",
    "            continue\n",
    "        elif not 2010 <= int(p_info_dict['iyr']) <= 2020:\n",
    "            continue\n",
    "        elif not 2020 <= int(p_info_dict['eyr']) <= 2030:\n",
    "            continue\n",
    "        elif not ((('cm' in p_info_dict['hgt']) and (150 <= int(p_info_dict['hgt'][:-2]) <= 193))\n",
    "                  or ('in' in p_info_dict['hgt'] and (59 <= int(p_info_dict['hgt'][:-2]) <= 76))):\n",
    "            continue\n",
    "        elif re.fullmatch('#(?:[0-9a-f]{6})', p_info_dict['hcl']) is None:\n",
    "            continue\n",
    "        elif p_info_dict['ecl'] not in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']:\n",
    "            continue\n",
    "        elif not (p_info_dict['pid'].isnumeric() and len(p_info_dict['pid']) == 9):\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(p_info_dict, e)\n",
    "    valid_passports += 1\n",
    "    \n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 5\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'i'\n",
    "a.replace('i', '0')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('5.txt') as seat_file:\n",
    "    seats = seat_file.read()\n",
    "bin_seats = seats.replace('F', '0')\n",
    "bin_seats = bin_seats.replace('B', '1')\n",
    "bin_seats = bin_seats.replace('L', '0')\n",
    "bin_seats = bin_seats.replace('R', '1')\n",
    "rows = np.array([int(s[:-3], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "columns = np.array([int(s[-3:], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "seat_id = np.array([int(s, base=2) for s in bin_seats.split('\\n')])\n",
    "\n",
    "print((rows*8+columns).max(), seat_id.max()) # Both should produce same output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat_id.sort()\n",
    "seat_id[np.append(np.diff(seat_id) != 1, False)] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(set(group_answers.replace('\\n', ''))) for group_answers in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(functools.reduce(set.__and__, (set(individual_answer) for individual_answer in group.split('\\n'))))\n",
    "    for group in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 7\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outer_bags(bag_name):\n",
    "    outer_bag_index = bags['inner'].str.contains(bag_name)\n",
    "    if outer_bag_index.sum() == 0:\n",
    "        return set()\n",
    "    return set(bags['outer'][outer_bag_index]) | functools.reduce(set.__or__, (count_outer_bags(bag) for bag in bags['outer'][outer_bag_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags = pd.read_csv('7.txt', sep='bags contain ', names=['outer', 'inner'], engine='python')\n",
    "len(count_outer_bags('shiny gold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rules = {}\n",
    "with open('7.txt') as bag_rule_file:\n",
    "    for bag_rule in bag_rule_file:\n",
    "        bag_rule = bag_rule.strip('\\n')\n",
    "        bag_name = bag_rule[:bag_rule.index(' bags contain ')]\n",
    "        if bag_rule.endswith('contain no other bags.'):\n",
    "            bag_rules[bag_name] = []\n",
    "        else:\n",
    "            # I barely know what this line does but it works\n",
    "            inner_bags = re.split(' bags.| bags, | bag.| bag, ', bag_rule[bag_rule.index('s contain ')+len('s contain'):])\n",
    "            inner_bags.remove('')\n",
    "            bag_rules[bag_name] = [{'bag name': inner_bag[3:], 'count': int(inner_bag[1])} for inner_bag in inner_bags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def count_inner_bags(bag_name):\n",
    "    if bag_rules[bag_name]:\n",
    "        return (sum(inner_bag['count']*count_inner_bags(inner_bag['bag name']) \n",
    "                   for inner_bag in bag_rules[bag_name]) + 1)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_inner_bags('shiny gold')-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 8\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = pd.read_csv('8.txt', sep=' ', names=['instruction', 'value'])\n",
    "visited_instructions = []\n",
    "i = 0\n",
    "acc = 0\n",
    "while i not in visited_instructions:\n",
    "    visited_instructions += [i]\n",
    "    if instructions.loc[i, 'instruction'] == 'acc':\n",
    "        acc += instructions.loc[i, 'value']\n",
    "        i += 1\n",
    "    elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "        i += instructions.loc[i, 'value']\n",
    "    else:\n",
    "        i += 1\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_instructions(instructions):\n",
    "    visited_instructions = []\n",
    "    i = 0\n",
    "    acc = 0\n",
    "    \n",
    "    while (i not in visited_instructions) and (i <= instructions.index[-1]):\n",
    "        visited_instructions += [i]\n",
    "        if instructions.loc[i, 'instruction'] == 'acc':\n",
    "            acc += instructions.loc[i, 'value']\n",
    "            i += 1\n",
    "            continue\n",
    "        elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "            i += instructions.loc[i, 'value']    \n",
    "        else:\n",
    "            i += 1\n",
    "    return i, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for change_index in instructions.query(\"instruction == 'jmp' or instruction == 'nop'\").index:\n",
    "    modified_instructions = instructions.copy()\n",
    "    modified_instructions.loc[change_index, 'instruction'] = 'jmp' if modified_instructions.loc[change_index, 'instruction'] == 'nop' else 'nop'\n",
    "    i, acc = do_instructions(modified_instructions)\n",
    "    if i > modified_instructions.index[-1]:\n",
    "        print(acc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 9\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('9.txt') as "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advent-of-code [conda env:env-2]",
   "language": "python",
   "name": "conda-env-env-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
