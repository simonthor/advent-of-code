{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import functools\n",
    "import awkward as ak\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1.txt') as numberfile:\n",
    "    numbers = np.array(numberfile.read().split(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    if (product := numbers[numbers + i == 2020] * i).size > 0:\n",
    "        print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(numbers):\n",
    "    for m in numbers[i:]:\n",
    "        if (product := numbers[numbers + n + m == 2020] * n * m).size > 0:\n",
    "            print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = pd.read_csv('2.txt', sep=' |-|: ', \n",
    "                        names=['min_counts', 'max_counts', 'character', 'password'], \n",
    "                        engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if entry.min_counts <= entry.password.count(entry.character) <= entry.max_counts:\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords.rename(columns={'min_counts': 'first_index', 'max_counts': 'last_index'}, inplace=True)\n",
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if (entry.password[entry.first_index-1] == entry.character) ^ (entry.password[entry.last_index-1] == entry.character):\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counter = 0\n",
    "index = 0\n",
    "slope = 3\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += (row[index] == '#')\n",
    "        index = (index + slope) % (len(row))\n",
    "print(tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = np.arange(1, 8, 2, dtype='int64')\n",
    "index = np.zeros_like(slope)\n",
    "tree_counter = np.zeros_like(slope)\n",
    "\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += [row[i] == '#' for i in index]\n",
    "        index = (index + slope) % (len(row))\n",
    "\n",
    "# Special case\n",
    "s_slope = 1\n",
    "s_index = 0\n",
    "s_tree_counter = 0\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in itertools.islice(tree_pattern_file, 0, None, 2):\n",
    "        row = row[:-1]\n",
    "        s_tree_counter += (row[s_index] == '#')\n",
    "        s_index = (s_index + s_slope) % (len(row))\n",
    "print(tree_counter.prod() * s_tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "pass_port_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    valid_passports += all(key in p_info for key in pass_port_keys)\n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(passport_info):\n",
    "    for info in passport_info.split():\n",
    "        yield info.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "passport_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    p_info_dict = {key: value for key, value in create_dict(p_info)}\n",
    "    # Guard clauses for input validation\n",
    "    try:\n",
    "        if not (set(p_info_dict.keys()) | set(('cid',))) == set(passport_keys):\n",
    "            continue\n",
    "        elif not 1920 <= int(p_info_dict['byr']) <= 2002:\n",
    "            continue\n",
    "        elif not 2010 <= int(p_info_dict['iyr']) <= 2020:\n",
    "            continue\n",
    "        elif not 2020 <= int(p_info_dict['eyr']) <= 2030:\n",
    "            continue\n",
    "        elif not ((('cm' in p_info_dict['hgt']) and (150 <= int(p_info_dict['hgt'][:-2]) <= 193))\n",
    "                  or ('in' in p_info_dict['hgt'] and (59 <= int(p_info_dict['hgt'][:-2]) <= 76))):\n",
    "            continue\n",
    "        elif re.fullmatch('#(?:[0-9a-f]{6})', p_info_dict['hcl']) is None:\n",
    "            continue\n",
    "        elif p_info_dict['ecl'] not in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']:\n",
    "            continue\n",
    "        elif not (p_info_dict['pid'].isnumeric() and len(p_info_dict['pid']) == 9):\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(p_info_dict, e)\n",
    "    valid_passports += 1\n",
    "    \n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 5\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'i'\n",
    "a.replace('i', '0')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('5.txt') as seat_file:\n",
    "    seats = seat_file.read()\n",
    "bin_seats = seats.replace('F', '0')\n",
    "bin_seats = bin_seats.replace('B', '1')\n",
    "bin_seats = bin_seats.replace('L', '0')\n",
    "bin_seats = bin_seats.replace('R', '1')\n",
    "rows = np.array([int(s[:-3], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "columns = np.array([int(s[-3:], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "seat_id = np.array([int(s, base=2) for s in bin_seats.split('\\n')])\n",
    "\n",
    "print((rows*8+columns).max(), seat_id.max()) # Both should produce same output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat_id.sort()\n",
    "seat_id[np.append(np.diff(seat_id) != 1, False)] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(set(group_answers.replace('\\n', ''))) for group_answers in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(functools.reduce(set.__and__, (set(individual_answer) for individual_answer in group.split('\\n'))))\n",
    "    for group in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 7\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outer_bags(bag_name):\n",
    "    outer_bag_index = bags['inner'].str.contains(bag_name)\n",
    "    if outer_bag_index.sum() == 0:\n",
    "        return set()\n",
    "    return set(bags['outer'][outer_bag_index]) | functools.reduce(set.__or__, (count_outer_bags(bag) for bag in bags['outer'][outer_bag_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags = pd.read_csv('7.txt', sep='bags contain ', names=['outer', 'inner'], engine='python')\n",
    "len(count_outer_bags('shiny gold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rules = {}\n",
    "with open('7.txt') as bag_rule_file:\n",
    "    for bag_rule in bag_rule_file:\n",
    "        bag_rule = bag_rule.strip('\\n')\n",
    "        bag_name = bag_rule[:bag_rule.index(' bags contain ')]\n",
    "        if bag_rule.endswith('contain no other bags.'):\n",
    "            bag_rules[bag_name] = []\n",
    "        else:\n",
    "            # I barely know what this line does but it works\n",
    "            inner_bags = re.split(' bags.| bags, | bag.| bag, ', bag_rule[bag_rule.index('s contain ')+len('s contain'):])\n",
    "            inner_bags.remove('')\n",
    "            bag_rules[bag_name] = [{'bag name': inner_bag[3:], 'count': int(inner_bag[1])} for inner_bag in inner_bags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=len(bag_rules))\n",
    "def count_inner_bags(bag_name):\n",
    "    if bag_rules[bag_name]:\n",
    "        return (sum(inner_bag['count']*count_inner_bags(inner_bag['bag name']) \n",
    "                   for inner_bag in bag_rules[bag_name]) + 1)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_inner_bags('shiny gold')-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 8\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = pd.read_csv('8.txt', sep=' ', names=['instruction', 'value'])\n",
    "visited_instructions = []\n",
    "i = 0\n",
    "acc = 0\n",
    "while i not in visited_instructions:\n",
    "    visited_instructions += [i]\n",
    "    if instructions.loc[i, 'instruction'] == 'acc':\n",
    "        acc += instructions.loc[i, 'value']\n",
    "        i += 1\n",
    "    elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "        i += instructions.loc[i, 'value']\n",
    "    else:\n",
    "        i += 1\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_instructions(instructions):\n",
    "    visited_instructions = []\n",
    "    i = 0\n",
    "    acc = 0\n",
    "    \n",
    "    while (i not in visited_instructions) and (i <= instructions.index[-1]):\n",
    "        visited_instructions += [i]\n",
    "        if instructions.loc[i, 'instruction'] == 'acc':\n",
    "            acc += instructions.loc[i, 'value']\n",
    "            i += 1\n",
    "            continue\n",
    "        elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "            i += instructions.loc[i, 'value']    \n",
    "        else:\n",
    "            i += 1\n",
    "    return i, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for change_index in instructions.query(\"instruction == 'jmp' or instruction == 'nop'\").index:\n",
    "    modified_instructions = instructions.copy()\n",
    "    modified_instructions.loc[change_index, 'instruction'] = 'jmp' if modified_instructions.loc[change_index, 'instruction'] == 'nop' else 'nop'\n",
    "    i, acc = do_instructions(modified_instructions)\n",
    "    if i > modified_instructions.index[-1]:\n",
    "        print(acc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 9\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmas_data = np.loadtxt('9.txt', dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(xmas_data[25:]):\n",
    "    combinations = np.array([combination for combination in itertools.combinations(xmas_data[i:i+25], 2)], dtype=np.int64)\n",
    "    if value not in combinations.sum(axis=1):\n",
    "        print(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for low_i, high_i in itertools.combinations(range(i), 2):\n",
    "    contiguous_set = xmas_data[low_i:high_i]\n",
    "    if contiguous_set.sum() == value:\n",
    "        print(contiguous_set.min()+contiguous_set.max())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 10\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jolts =np.loadtxt('10.txt', dtype=np.int64)\n",
    "jolts = np.append(jolts, jolts.max()+3)\n",
    "jolts = np.insert(jolts, 0, 0)\n",
    "jolts.sort()\n",
    "jolt_diff = np.diff(jolts)\n",
    "(jolt_diff == 3).sum() * (jolt_diff == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoveable = (jolt_diff == 3).nonzero()[0] + 1\n",
    "all_possible_configurations = 1\n",
    "for start_i, end_i in zip(np.insert(nonmoveable[:-1], 0, 0)+1, nonmoveable):\n",
    "    max_int = end_i - start_i - 1\n",
    "    if max_int > 0:\n",
    "        possible_subsets = 0\n",
    "        \n",
    "        for picks in (((np.arange(2**max_int)[:,None] & (1 << np.arange(max_int)))) > 0).astype(bool).tolist():\n",
    "            if (np.diff(jolts[start_i-1:end_i][np.concatenate(((True,), picks, (True,)))]) <= 3).all():\n",
    "                possible_subsets += 1\n",
    "        all_possible_configurations *= possible_subsets\n",
    "all_possible_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below gives the same solution as above but using Awkward Array, thus making the code vectorized. \n",
    "I was not sure how to make this efficient as the typical ak.Array(np_array) does not create a variable row length array.\n",
    "I solved it by calling `extended_possible_subsets.tolist()` but I don't think this is efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoveable = (jolt_diff == 3).nonzero()[0] + 1\n",
    "all_possible_configurations = 1\n",
    "for start_i, end_i in zip(np.insert(nonmoveable[:-1], 0, 0)+1, nonmoveable):\n",
    "    max_int = end_i - start_i - 1\n",
    "    if max_int > 0:\n",
    "        possible_subsets = (((np.arange(2**max_int)[:,None] & (1 << np.arange(max_int)))) > 0).astype(bool)\n",
    "        extended_possible_subsets = np.ones((2**max_int, max_int+2)).astype(bool)\n",
    "        extended_possible_subsets[:, 1:-1] = possible_subsets\n",
    "        allowed_subsets = ak.Array(np.tile(jolts[start_i-1:end_i], (2**max_int, 1)))[ak.Array(extended_possible_subsets.tolist())]\n",
    "        allowed_subset_count = int(ak.sum(ak.all((allowed_subsets[:, 1:] - allowed_subsets[:, :-1]) <= 3, axis=1)))\n",
    "        all_possible_configurations *= allowed_subset_count\n",
    "all_possible_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 11\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_seat_state = []\n",
    "with open('11.txt') as original_seat_file:\n",
    "    for row in original_seat_file:\n",
    "        original_seat_state.append(list(row)[:-1])\n",
    "state_str = np.array(original_seat_state, dtype=str)\n",
    "state = np.zeros(np.array(state_str.shape)+2, dtype=bool)\n",
    "seat_locs = np.array((state_str == 'L').nonzero()).T + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def next_seat_configuration(seat_locs, state):\n",
    "    new_state = state.copy()\n",
    "    for index in (seat_locs.T+1):\n",
    "        seats_around = state[index[0]-1:index[0]+2, index[1]-1:index[1]+2]\n",
    "        if (state[index[0], index[1]] \n",
    "            and (seats_around.sum() >= 5)):\n",
    "            new_state[index[0], index[1]] = False\n",
    "        elif not seats_around.any():\n",
    "            new_state[index[0], index[1]] = True\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    new_state = next_seat_configuration(seat_locs, state)\n",
    "    if (state == new_state).all():\n",
    "        print((state == True).sum())\n",
    "        break\n",
    "    state = new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@nb.njit\n",
    "def find_seats_around(seat_locs, state, index):\n",
    "    seats_around = np.zeros(8)\n",
    "    for i, motion in enumerate(np.array([[0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, 1]])):\n",
    "        diagonal = index + motion\n",
    "        while (not (diagonal == seat_locs).all(axis=1).any()) and ((0 < diagonal) & (diagonal < np.array(state.shape)-1)).all():\n",
    "            diagonal += motion\n",
    "        seats_around[i] = state[tuple(diagonal)]\n",
    "    return seats_around\n",
    "\n",
    "#@nb.njit\n",
    "def next_seat_configuration2(seat_locs, state):\n",
    "    new_state = state.copy()\n",
    "    for index in (seat_locs):\n",
    "        seats_around = find_seats_around(seat_locs, state, index)\n",
    "        if (state[index[0], index[1]] and (seats_around.sum() >= 6)):\n",
    "            new_state[index[0], index[1]] = False\n",
    "        elif not seats_around.any():\n",
    "            new_state[index[0], index[1]] = True\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "seat_locs = np.array((state_str == 'L').nonzero()).T + 1\n",
    "# Only allow 100 loops as it should not do require more than that. Mainly for debugging purposes\n",
    "i=0\n",
    "while i < 100:\n",
    "    new_state = next_seat_configuration2(seat_locs, state)\n",
    "    if (state == new_state).all():\n",
    "        print(state.sum())\n",
    "        break\n",
    "    state = new_state\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 00001\n",
    "# 00100\n",
    "# 00001\n",
    "# 00010\n",
    "# 10100\n",
    "np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[(2, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array((1, 1))\n",
    "seats_around = np.zeros(8)\n",
    "for i, motion in enumerate(np.array([[0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, 1]])):\n",
    "    diagonal = index + motion\n",
    "    while (not (diagonal == seat_locs).all(axis=1).any()) and ((0 < diagonal) & (diagonal < np.array(state.shape))).all():\n",
    "        diagonal += motion\n",
    "    seats_around[i] = state[tuple(diagonal)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advent-of-code [conda env:env-2]",
   "language": "python",
   "name": "conda-env-env-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
