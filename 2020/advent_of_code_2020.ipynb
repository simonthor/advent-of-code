{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advent of Code 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import re\n",
    "import functools\n",
    "import awkward as ak\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 1\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1.txt') as numberfile:\n",
    "    numbers = np.array(numberfile.read().split(), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numbers:\n",
    "    if (product := numbers[numbers + i == 2020] * i).size > 0:\n",
    "        print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(numbers):\n",
    "    for m in numbers[i:]:\n",
    "        if (product := numbers[numbers + n + m == 2020] * n * m).size > 0:\n",
    "            print(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords = pd.read_csv('2.txt', sep=' |-|: ', \n",
    "                        names=['min_counts', 'max_counts', 'character', 'password'], \n",
    "                        engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if entry.min_counts <= entry.password.count(entry.character) <= entry.max_counts:\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwords.rename(columns={'min_counts': 'first_index', 'max_counts': 'last_index'}, inplace=True)\n",
    "valid_passwords = 0\n",
    "for entry in passwords.itertuples():\n",
    "    if (entry.password[entry.first_index-1] == entry.character) ^ (entry.password[entry.last_index-1] == entry.character):\n",
    "        valid_passwords += 1\n",
    "print(valid_passwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 3\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_counter = 0\n",
    "index = 0\n",
    "slope = 3\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += (row[index] == '#')\n",
    "        index = (index + slope) % (len(row))\n",
    "print(tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = np.arange(1, 8, 2, dtype='int64')\n",
    "index = np.zeros_like(slope)\n",
    "tree_counter = np.zeros_like(slope)\n",
    "\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in tree_pattern_file:\n",
    "        row = row[:-1]\n",
    "        tree_counter += [row[i] == '#' for i in index]\n",
    "        index = (index + slope) % (len(row))\n",
    "\n",
    "# Special case\n",
    "s_slope = 1\n",
    "s_index = 0\n",
    "s_tree_counter = 0\n",
    "with open('3.txt') as tree_pattern_file:\n",
    "    for row in itertools.islice(tree_pattern_file, 0, None, 2):\n",
    "        row = row[:-1]\n",
    "        s_tree_counter += (row[s_index] == '#')\n",
    "        s_index = (s_index + s_slope) % (len(row))\n",
    "print(tree_counter.prod() * s_tree_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 4\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "pass_port_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    valid_passports += all(key in p_info for key in pass_port_keys)\n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(passport_info):\n",
    "    for info in passport_info.split():\n",
    "        yield info.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt') as passport_file:\n",
    "    passports = passport_file.read()\n",
    "passport_keys = ['byr','iyr', 'eyr', 'hgt', 'hcl', 'ecl', 'pid', 'cid']\n",
    "valid_passports = 0\n",
    "for p_info in passports.split('\\n\\n'):\n",
    "    p_info_dict = {key: value for key, value in create_dict(p_info)}\n",
    "    # Guard clauses for input validation\n",
    "    try:\n",
    "        if not (set(p_info_dict.keys()) | set(('cid',))) == set(passport_keys):\n",
    "            continue\n",
    "        elif not 1920 <= int(p_info_dict['byr']) <= 2002:\n",
    "            continue\n",
    "        elif not 2010 <= int(p_info_dict['iyr']) <= 2020:\n",
    "            continue\n",
    "        elif not 2020 <= int(p_info_dict['eyr']) <= 2030:\n",
    "            continue\n",
    "        elif not ((('cm' in p_info_dict['hgt']) and (150 <= int(p_info_dict['hgt'][:-2]) <= 193))\n",
    "                  or ('in' in p_info_dict['hgt'] and (59 <= int(p_info_dict['hgt'][:-2]) <= 76))):\n",
    "            continue\n",
    "        elif re.fullmatch('#(?:[0-9a-f]{6})', p_info_dict['hcl']) is None:\n",
    "            continue\n",
    "        elif p_info_dict['ecl'] not in ['amb', 'blu', 'brn', 'gry', 'grn', 'hzl', 'oth']:\n",
    "            continue\n",
    "        elif not (p_info_dict['pid'].isnumeric() and len(p_info_dict['pid']) == 9):\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(p_info_dict, e)\n",
    "    valid_passports += 1\n",
    "    \n",
    "print(valid_passports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 5\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'i'\n",
    "a.replace('i', '0')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('5.txt') as seat_file:\n",
    "    seats = seat_file.read()\n",
    "bin_seats = seats.replace('F', '0')\n",
    "bin_seats = bin_seats.replace('B', '1')\n",
    "bin_seats = bin_seats.replace('L', '0')\n",
    "bin_seats = bin_seats.replace('R', '1')\n",
    "rows = np.array([int(s[:-3], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "columns = np.array([int(s[-3:], base=2) for s in bin_seats.split('\\n')], dtype=int)\n",
    "seat_id = np.array([int(s, base=2) for s in bin_seats.split('\\n')])\n",
    "\n",
    "print((rows*8+columns).max(), seat_id.max()) # Both should produce same output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seat_id.sort()\n",
    "seat_id[np.append(np.diff(seat_id) != 1, False)] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(set(group_answers.replace('\\n', ''))) for group_answers in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(functools.reduce(set.__and__, (set(individual_answer) for individual_answer in group.split('\\n'))))\n",
    "    for group in open('6.txt').read().split('\\n\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 7\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outer_bags(bag_name):\n",
    "    outer_bag_index = bags['inner'].str.contains(bag_name)\n",
    "    if outer_bag_index.sum() == 0:\n",
    "        return set()\n",
    "    return set(bags['outer'][outer_bag_index]) | functools.reduce(set.__or__, (count_outer_bags(bag) for bag in bags['outer'][outer_bag_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags = pd.read_csv('7.txt', sep='bags contain ', names=['outer', 'inner'], engine='python')\n",
    "len(count_outer_bags('shiny gold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_rules = {}\n",
    "with open('7.txt') as bag_rule_file:\n",
    "    for bag_rule in bag_rule_file:\n",
    "        bag_rule = bag_rule.strip('\\n')\n",
    "        bag_name = bag_rule[:bag_rule.index(' bags contain ')]\n",
    "        if bag_rule.endswith('contain no other bags.'):\n",
    "            bag_rules[bag_name] = []\n",
    "        else:\n",
    "            # I barely know what this line does but it works\n",
    "            inner_bags = re.split(' bags.| bags, | bag.| bag, ', bag_rule[bag_rule.index('s contain ')+len('s contain'):])\n",
    "            inner_bags.remove('')\n",
    "            bag_rules[bag_name] = [{'bag name': inner_bag[3:], 'count': int(inner_bag[1])} for inner_bag in inner_bags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=len(bag_rules))\n",
    "def count_inner_bags(bag_name):\n",
    "    if bag_rules[bag_name]:\n",
    "        return (sum(inner_bag['count']*count_inner_bags(inner_bag['bag name']) \n",
    "                   for inner_bag in bag_rules[bag_name]) + 1)\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_inner_bags('shiny gold')-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 8\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = pd.read_csv('8.txt', sep=' ', names=['instruction', 'value'])\n",
    "visited_instructions = []\n",
    "i = 0\n",
    "acc = 0\n",
    "while i not in visited_instructions:\n",
    "    visited_instructions += [i]\n",
    "    if instructions.loc[i, 'instruction'] == 'acc':\n",
    "        acc += instructions.loc[i, 'value']\n",
    "        i += 1\n",
    "    elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "        i += instructions.loc[i, 'value']\n",
    "    else:\n",
    "        i += 1\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_instructions(instructions):\n",
    "    visited_instructions = []\n",
    "    i = 0\n",
    "    acc = 0\n",
    "    \n",
    "    while (i not in visited_instructions) and (i <= instructions.index[-1]):\n",
    "        visited_instructions += [i]\n",
    "        if instructions.loc[i, 'instruction'] == 'acc':\n",
    "            acc += instructions.loc[i, 'value']\n",
    "            i += 1\n",
    "            continue\n",
    "        elif instructions.loc[i, 'instruction'] == 'jmp':\n",
    "            i += instructions.loc[i, 'value']    \n",
    "        else:\n",
    "            i += 1\n",
    "    return i, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for change_index in instructions.query(\"instruction == 'jmp' or instruction == 'nop'\").index:\n",
    "    modified_instructions = instructions.copy()\n",
    "    modified_instructions.loc[change_index, 'instruction'] = 'jmp' if modified_instructions.loc[change_index, 'instruction'] == 'nop' else 'nop'\n",
    "    i, acc = do_instructions(modified_instructions)\n",
    "    if i > modified_instructions.index[-1]:\n",
    "        print(acc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 9\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmas_data = np.loadtxt('9.txt', dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, value in enumerate(xmas_data[25:]):\n",
    "    combinations = np.array([combination for combination in itertools.combinations(xmas_data[i:i+25], 2)], dtype=np.int64)\n",
    "    if value not in combinations.sum(axis=1):\n",
    "        print(value)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for low_i, high_i in itertools.combinations(range(i), 2):\n",
    "    contiguous_set = xmas_data[low_i:high_i]\n",
    "    if contiguous_set.sum() == value:\n",
    "        print(contiguous_set.min()+contiguous_set.max())\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 10\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jolts =np.loadtxt('10.txt', dtype=np.int64)\n",
    "jolts = np.append(jolts, jolts.max()+3)\n",
    "jolts = np.insert(jolts, 0, 0)\n",
    "jolts.sort()\n",
    "jolt_diff = np.diff(jolts)\n",
    "(jolt_diff == 3).sum() * (jolt_diff == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoveable = (jolt_diff == 3).nonzero()[0] + 1\n",
    "all_possible_configurations = 1\n",
    "for start_i, end_i in zip(np.insert(nonmoveable[:-1], 0, 0)+1, nonmoveable):\n",
    "    max_int = end_i - start_i - 1\n",
    "    if max_int > 0:\n",
    "        possible_subsets = 0\n",
    "        \n",
    "        for picks in (((np.arange(2**max_int)[:,None] & (1 << np.arange(max_int)))) > 0).astype(bool).tolist():\n",
    "            if (np.diff(jolts[start_i-1:end_i][np.concatenate(((True,), picks, (True,)))]) <= 3).all():\n",
    "                possible_subsets += 1\n",
    "        all_possible_configurations *= possible_subsets\n",
    "all_possible_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below gives the same solution as above but using Awkward Array, thus making the code vectorized. \n",
    "I was not sure how to make this efficient as the typical ak.Array(np_array) does not create a variable row length array.\n",
    "I solved it by calling `extended_possible_subsets.tolist()` but I don't think this is efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoveable = (jolt_diff == 3).nonzero()[0] + 1\n",
    "all_possible_configurations = 1\n",
    "for start_i, end_i in zip(np.insert(nonmoveable[:-1], 0, 0)+1, nonmoveable):\n",
    "    max_int = end_i - start_i - 1\n",
    "    if max_int > 0:\n",
    "        possible_subsets = (((np.arange(2**max_int)[:,None] & (1 << np.arange(max_int)))) > 0).astype(bool)\n",
    "        extended_possible_subsets = np.ones((2**max_int, max_int+2)).astype(bool)\n",
    "        extended_possible_subsets[:, 1:-1] = possible_subsets\n",
    "        allowed_subsets = ak.Array(np.tile(jolts[start_i-1:end_i], (2**max_int, 1)))[ak.Array(extended_possible_subsets.tolist())]\n",
    "        allowed_subset_count = int(ak.sum(ak.all((allowed_subsets[:, 1:] - allowed_subsets[:, :-1]) <= 3, axis=1)))\n",
    "        all_possible_configurations *= allowed_subset_count\n",
    "all_possible_configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 11\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_seat_state = []\n",
    "with open('11.txt') as original_seat_file:\n",
    "    for row in original_seat_file:\n",
    "        original_seat_state.append(list(row)[:-1])\n",
    "\n",
    "state_str_withoutpad = np.array(original_seat_state, dtype=str)\n",
    "state_str = np.full(np.array(state_str.shape)+2, '.')\n",
    "state_str[1:-1, 1:-1] = state_str_withoutpad\n",
    "state = np.zeros(state_str.shape, dtype=bool)\n",
    "seat_locs = np.array((state_str == 'L').nonzero()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def next_seat_configuration(seat_locs, state):\n",
    "    new_state = state.copy()\n",
    "    for index in (seat_locs):\n",
    "        seats_around = state[index[0]-1:index[0]+2, index[1]-1:index[1]+2]\n",
    "        if (state[index[0], index[1]] \n",
    "            and (seats_around.sum() >= 5)):\n",
    "            new_state[index[0], index[1]] = False\n",
    "        elif not seats_around.any():\n",
    "            new_state[index[0], index[1]] = True\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    new_state = next_seat_configuration(seat_locs, state)\n",
    "    if (state == new_state).all():\n",
    "        print((state == True).sum())\n",
    "        break\n",
    "    state = new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2\n",
    "Not done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@nb.njit\n",
    "def find_seats_around(seat_locs, state, index):\n",
    "    seats_around = np.zeros((2, 8), dtype=int)\n",
    "    for i, motion in enumerate(np.array([[0, 1], [0, -1], [1, 0], [1, 1], [1, -1], [-1, 0], [-1, 1], [-1, 1]], dtype=int)):\n",
    "        diagonal = index + motion\n",
    "        while (state_str[tuple(diagonal)] == '.') and ((0 < diagonal) & (diagonal < np.array(state.shape)-1)).all():\n",
    "            diagonal += motion\n",
    "        seats_around[:, i] = diagonal\n",
    "    return seats_around\n",
    "\n",
    "#@nb.njit\n",
    "#def next_seat_configuration2(seat_locs, state):\n",
    "#    new_state = state.copy()\n",
    "#    for index in (seat_locs):\n",
    "#        seats_around = find_seats_around(seat_locs, state, index)\n",
    "#        if (state[index[0], index[1]] and (seats_around.sum() >= 6)):\n",
    "#            new_state[index[0], index[1]] = False\n",
    "#        elif not seats_around.any():\n",
    "#            new_state[index[0], index[1]] = True\n",
    "#    return new_state\n",
    "\n",
    "def next_seat_configuration2(seat_locs, all_seats_around, state):\n",
    "    new_state = state.copy()\n",
    "    for seat, seats_around in zip(seat_locs, all_seats_around):\n",
    "        if (state[tuple(seat)] and (state[seats_around[0, :], seats_around[1, :]].sum() >= 6)):\n",
    "            new_state[tuple(seat)] = False\n",
    "        elif not state[seats_around[0, :], seats_around[1, :]].any():\n",
    "            new_state[tuple(seat)] = True\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seats_around = np.zeros((*seat_locs.shape, 8), dtype=int)\n",
    "for i, seat in enumerate(seat_locs):\n",
    "    all_seats_around[i, ...] = find_seats_around(seat_locs, state, seat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i < 100:\n",
    "    new_state = next_seat_configuration2(seat_locs, all_seats_around, state)\n",
    "    if (state == new_state).all():\n",
    "        print(state.sum())\n",
    "        break\n",
    "    state = new_state\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "seat_locs = np.array((state_str == 'L').nonzero()).T + 1\n",
    "# Only allow 100 loops as it should not do require more than that. Mainly for debugging purposes\n",
    "i=0\n",
    "while i < 100:\n",
    "    new_state = next_seat_configuration2(seat_locs, state)\n",
    "    if (state == new_state).all():\n",
    "        print(state.sum())\n",
    "        break\n",
    "    state = new_state\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 12\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ship:\n",
    "    def __init__(self, start_direction: str, start_position: complex):\n",
    "        # TODO: change start_position to tuple of str\n",
    "        self.direction_converter = {'N':1j, 'E':1, 'S':-1j, 'W':-1}\n",
    "        self.rotation_converter = {'L':1j, 'R':-1j}\n",
    "        self.direction = self.direction_converter[start_direction]\n",
    "        self.start_position = start_position\n",
    "        self.position = start_position\n",
    "        \n",
    "    def move(self, instructions: list):\n",
    "        # TODO: to make this efficient, I should probably convert all instructions to numbers first\n",
    "        # TODO: use reduce?\n",
    "        for i in instructions:\n",
    "            instruction, amount = i[0], int(i[1:])\n",
    "            if instruction in self.rotation_converter.keys():\n",
    "                self.direction *= self.rotation_converter[instruction]**(amount//90)\n",
    "            elif instruction in self.direction_converter.keys():\n",
    "                self.position += self.direction_converter[instruction]*amount\n",
    "            elif instruction == 'F':\n",
    "                self.position += self.direction*amount\n",
    "            else:\n",
    "                raise KeyError(f\"invalid instruction '{instruction}'\")\n",
    "    \n",
    "    @property\n",
    "    def manhattan_distance(self):\n",
    "        complex_distance = self.position - self.start_position\n",
    "        return abs(complex_distance.real) + abs(complex_distance.imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12.txt') as instruction_file:\n",
    "    instructions = instruction_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ferry = Ship(start_direction='E', start_position=0)\n",
    "ferry.move(instructions)\n",
    "ferry.manhattan_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WayPointShip(Ship):\n",
    "    def __init__(self, start_position: complex, start_waypoint: complex, start_direction: str = 'E'):\n",
    "        # start_direction will not be used by this class\n",
    "        super().__init__(start_direction, start_position)\n",
    "        # TODO: change waypoint to tuple of str and convert to complex\n",
    "        self.waypoint = start_waypoint\n",
    "        \n",
    "    def move(self, instructions: list):\n",
    "        for i in instructions:\n",
    "            instruction, amount = i[0], int(i[1:])\n",
    "            if instruction in self.rotation_converter.keys():\n",
    "                self.waypoint *= self.rotation_converter[instruction]**(amount//90)\n",
    "            elif instruction in self.direction_converter.keys():\n",
    "                self.waypoint += self.direction_converter[instruction]*amount\n",
    "            elif instruction == 'F':\n",
    "                self.position += self.waypoint*amount\n",
    "            else:\n",
    "                raise KeyError(f\"invalid instruction '{instruction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waypoint_ferry = WayPointShip(start_position=0, start_waypoint=10+1j)\n",
    "waypoint_ferry.move(instructions)\n",
    "waypoint_ferry.manhattan_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 13\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('13.txt') as notes:\n",
    "    time = int(notes.readline().strip('\\n'))\n",
    "    busses = np.array([int(bus_id) for bus_id in notes.readline().split(',')\n",
    "              if bus_id != 'x'], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_arrival_time = np.abs(time % busses - busses)\n",
    "busses[bus_arrival_time.argmin()]* bus_arrival_time.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('13.txt') as notes:\n",
    "    notes.readline()\n",
    "    busses_with_shift = np.array([(int(bus_id), i%int(bus_id)) \n",
    "                       for i, bus_id in enumerate(notes.readline().split(',')) \n",
    "                       if bus_id.isnumeric()], dtype=np.int64).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busses_with_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def find_t(busses_with_shift, min_val):\n",
    "    longest_bus = busses_with_shift[:, busses_with_shift[0, :].argmax()]\n",
    "    min_val = 100000000000000\n",
    "    (min_val + longest_bus[1]) % longest_bus[0] + min_val\n",
    "\n",
    "    t = longest_bus[0] * ((min_val//longest_bus[0])+1) - longest_bus[1]\n",
    "\n",
    "    while t < min_val*100:\n",
    "        if ((t + busses_with_shift[1, :]) % busses_with_shift[0, :] == 0).all():\n",
    "            return t\n",
    "            break\n",
    "        t += longest_bus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_t(busses_with_shift, 100000000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_bus = busses_with_shift[:, busses_with_shift[0, :].argmax()]\n",
    "min_val = 100000000000000\n",
    "(min_val + longest_bus[1]) % longest_bus[0] + min_val\n",
    "\n",
    "t = longest_bus[0] * ((min_val//longest_bus[0])+1) - longest_bus[1]\n",
    "\n",
    "while t < np.iinfo(np.int64).max-longest_bus[0]:\n",
    "    if ((t + busses_with_shift[1, :]) % busses_with_shift[0, :] == 0).all():\n",
    "        print(t)\n",
    "        break\n",
    "    t += longest_bus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_bus = busses_with_shift[:, busses_with_shift[0, :].argmax()]\n",
    "min_val = 100000000000000\n",
    "\n",
    "((min_val + longest_bus[1]) % longest_bus[0] + min_val + longest_bus[1]) % longest_bus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closestNumber(n, m) : \n",
    "    # Find the quotient \n",
    "    q = n//m\n",
    "      \n",
    "    # 1st possible closest number \n",
    "    n1 = m * (q+1) \n",
    "    return n1  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = longest_bus[0] * ((min_val//longest_bus[0])+1) -longest_bus[1]\n",
    "(t + longest_bus[1]) % longest_bus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 14\n",
    "### part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = {}\n",
    "int_size = 36\n",
    "with open('14.txt') as bitmask_file:\n",
    "    for line in bitmask_file:\n",
    "        if line[:4] == 'mask':\n",
    "            mask = np.array([int(i)  if i != 'X' else np.nan for i in line[7:-1]])\n",
    "        elif line[:3] == 'mem':\n",
    "            memory_loc = int(re.search(r'\\[(.*?)\\]', line).group(1))\n",
    "            value = int(line[line.index(' = ')+3:-1])\n",
    "            value_bin = np.array(list(np.binary_repr(value).zfill(int_size))).astype(np.int8)\n",
    "            masked_value_bin = np.where(np.isnan(mask), value_bin, mask).astype(np.uint64)\n",
    "            masked_value = (masked_value_bin*np.uint64(2)**np.arange(int_size-1, -1, -1).astype(np.uint64)).sum()            \n",
    "            memory[memory_loc] = masked_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(memory.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = {}\n",
    "int_size = 36\n",
    "with open('14.txt') as bitmask_file:\n",
    "    for line in bitmask_file:\n",
    "        # This loop is quite slow and takes a few seconds\n",
    "        if line[:4] == 'mask':\n",
    "            mask = np.array([int(i)  if i != 'X' else np.nan for i in line[7:-1]])\n",
    "        elif line[:3] == 'mem':\n",
    "            adress = int(re.search(r'\\[(.*?)\\]', line).group(1))\n",
    "            value = int(line[line.index(' = ')+3:-1])\n",
    "            adress_bin = np.array(list(np.binary_repr(adress).zfill(int_size))).astype(np.int8)\n",
    "            float_bit_count = np.isnan(mask).sum()\n",
    "            possible_float_states = (((np.arange(2**float_bit_count)[:,None] & (1 << np.arange(float_bit_count)))) > 0)\n",
    "            adress_bin[mask == 1] = 1\n",
    "            for float_state in possible_float_states:\n",
    "                adress_bin[np.isnan(mask)] = float_state\n",
    "                masked_adress = int((adress_bin*np.uint64(2)**np.arange(int_size-1, -1, -1).astype(np.uint64)).sum())\n",
    "                memory[masked_adress] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(memory.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advent-of-code [conda env:env-2]",
   "language": "python",
   "name": "conda-env-env-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
